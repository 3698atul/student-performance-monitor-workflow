{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOrPiEKcVqRLLKbRTkWmXlP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/3698atul/student-performance-monitor-workflow/blob/main/Mental_Health_Support_BOT_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViWkaxIzEemG",
        "outputId": "f0a58b43-62db-4638-c774-5222091112d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m59.5/59.5 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U google-generativeai gradio\n",
        "import os\n",
        "import gradio as gr\n",
        "import google.generativeai as genai\n",
        "from IPython.display import Markdown\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    from google.colab import userdata\n",
        "    GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "    os.environ['GOOGLE_API_KEY'] = GEMINI_API_KEY\n",
        "    genai.configure(api_key=GEMINI_API_KEY)\n"
      ],
      "metadata": {
        "id": "WQQnf8LdHHoH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel('gemini-2.5-pro')\n",
        "\n",
        "\n",
        "def generate_response(prompt_text):\n",
        "    \"\"\"\n",
        "    Generates a response from the Gemini model based on a prompt.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = model.generate_content(prompt_text)\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {e}\"\n",
        "\n",
        "def get_mood(user_input):\n",
        "    \"\"\"\n",
        "    Agent: Mood Analyzer\n",
        "    Analyzes the user's input to determine their mood.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    Analyze the sentiment and emotional state of the following text and return a single word that best describes the mood.\n",
        "    Examples:\n",
        "    Text: \"I'm feeling so overwhelmed with everything.\"\n",
        "    Mood: Overwhelmed\n",
        "\n",
        "    Text: \"Today was a really great day! I got so much done.\"\n",
        "    Mood: Happy\n",
        "\n",
        "    Text: \"I don't know what to do anymore. I just feel so lost.\"\n",
        "    Mood: Sad\n",
        "\n",
        "    Text: \"{user_input}\"\n",
        "    Mood:\n",
        "    \"\"\"\n",
        "    return generate_response(prompt)\n",
        "\n",
        "def get_self_care_suggestion(mood):\n",
        "    \"\"\"\n",
        "    Agent: Self-Care Recommender\n",
        "    Suggests a mental wellness activity based on the detected mood.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    Based on the following mood, suggest a simple and helpful mental wellness or self-care activity. Be brief and encouraging.\n",
        "    Mood: {mood}\n",
        "    Example:\n",
        "    Mood: Overwhelmed\n",
        "    Suggestion: Try a 5-minute guided breathing exercise to recenter yourself.\n",
        "\n",
        "    Mood: Anxious\n",
        "    Suggestion: Write down all your worries in a journal, then try to reframe one of them.\n",
        "\n",
        "    Mood: Sad\n",
        "    Suggestion: Listen to some calming music and allow yourself to feel your emotions.\n",
        "\n",
        "    Mood: Happy\n",
        "    Suggestion: Take a moment to appreciate what's going well.\n",
        "\n",
        "    Suggestion:\n",
        "    \"\"\"\n",
        "    return generate_response(prompt)\n",
        "\n",
        "def get_companion_response(user_input, mood):\n",
        "    \"\"\"\n",
        "    Agent: Companion\n",
        "    Generates an empathetic and supportive conversational response.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    You are a supportive and empathetic mental wellness companion. Your goal is to provide a non-judgmental and caring response.\n",
        "    Keep your responses concise and conversational. Do not give medical advice.\n",
        "    The user's current mood is detected as: {mood}.\n",
        "    User: {user_input}\n",
        "    Response:\n",
        "    \"\"\"\n",
        "    return generate_response(prompt)\n",
        "\n",
        "#Main chatbot function for Gradio\n",
        "def chatbot_response(history):\n",
        "    \"\"\"\n",
        "    Processes the user's latest message and generates a full response.\n",
        "    \"\"\"\n",
        "    user_message = history[-1][0]\n",
        "\n",
        "    # Agent 1 Mood Analyzer\n",
        "    mood = get_mood(user_message)\n",
        "\n",
        "    # Agent 2 Companion\n",
        "    companion_response = get_companion_response(user_message, mood)\n",
        "\n",
        "    # Agent 3 Self-Care Recommender\n",
        "    if mood.strip().lower() in ['overwhelmed', 'anxious', 'sad', 'stressed']:\n",
        "        wellness_suggestion = get_self_care_suggestion(mood)\n",
        "        full_response = f\"{companion_response}\\n\\n**Wellness Tip:** {wellness_suggestion}\"\n",
        "    else:\n",
        "        full_response = companion_response\n",
        "\n",
        "    # Update the last message in history with the bot's response\n",
        "    history[-1][1] = full_response\n",
        "    return history\n",
        "\n",
        "# Gradio UI\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# Mental Health Support Bot ü§ñüíö\")\n",
        "    gr.Markdown(\"Hi there! I'm here to listen. You can share what's on your mind, and I'll do my best to provide a supportive response and a helpful wellness tip.\")\n",
        "\n",
        "    chatbot = gr.Chatbot(label=\"Chatbot\")\n",
        "    msg = gr.Textbox(placeholder=\"How are you feeling today?\", label=\"Your Message\")\n",
        "    clear = gr.ClearButton([msg, chatbot])\n",
        "\n",
        "    # Function to update the chat history with the user's message\n",
        "    def add_message(user_message, history):\n",
        "        return \"\", history + [[user_message, None]]\n",
        "\n",
        "    # Gradio event handling\n",
        "    msg.submit(add_message, [msg, chatbot], [msg, chatbot], queue=False).then(\n",
        "        chatbot_response, chatbot, chatbot\n",
        "    )\n",
        "\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "id": "Ts21dOssFxmA",
        "outputId": "40f1b107-f4b9-48ef-f57e-8ba632df1bca"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3428232004.py:104: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot(label=\"Chatbot\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://e8db2311f26e69df74.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e8db2311f26e69df74.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://e8db2311f26e69df74.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "KImfiiINNRSt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}